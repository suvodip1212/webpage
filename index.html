<!DOCTYPE HTML>
<!--
    Strata by HTML5 UP
    html5up.net | @ajlkn
    Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
<head>
    <title>Suvodip Chakraborty</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes" />
    <link rel="stylesheet" href="assets/css/main.css" />
    
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-2D82EQPRPR"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-2D82EQPRPR');
    </script>

    <script>
        function darkTheme() {
            document.body.classList.toggle("dark-mode");
        }

        function trackCVDownload() {
            gtag("event", "cv_download");
        }
    </script>

    <style>
      html {
        scroll-behavior: smooth;
      }
    </style>
</head>
<body class="is-preload">

<!-- Header -->
<header id="header">
    <div class="inner" style="text-align: center;">
        <a href="#" class="image avatar">
            <img src="images/Suvodip_2.png" alt="Suvodip Chakraborty" />
        </a>
        <h1>Suvodip Chakraborty</h1>
        <h2>Postdoctoral Researcher, ETH Zurich</h2>
        <h3>Singapore-ETH Centre, CREATE TOWER, Singapore</h3>
        <h3>MS Signal Processing, Indian Institute of Technology, Kharagpur, India</h3>

        <ul class="icons" style="font-size: 1.5rem;">
            <li><a href="https://www.linkedin.com/in/suvodip-chakraborty-3b691813a/" target="_blank" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
            <li><a href="https://scholar.google.com/citations?user=T7ciEg8AAAAJ&hl=en/" target="_blank" class="icon brands fa-google-plus-g"><span class="label">Google Scholar</span></a></li>
            <li><a href="https://github.com/suvodip1212" target="_blank" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
            <li><a href="mailto:suvodip.107019@gmail.com" target="_blank" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
        </ul>

        <div>
            <input type="checkbox" id="dark-theme" name="dark-theme" onclick="darkTheme()">
            <label for="dark-theme">Dark theme</label>
        </div>
    </div>
</header>

<!-- Main -->
<div id="main">

    <!-- About Section -->
    <section id="one">
        <header class="major">
            <h2>About Me</h2>
        </header>
        <p>
            I am a postdoctoral researcher at ETH Zurich, specialising in human factors, resilience engineering, and collaborative human-computer interaction in complex, safety-critical systems. My PhD at the Singapore-ETH Centre focused on supporting sense-making and decision-making in traffic control rooms through advanced methods for cognitive load assessment, eye-tracking analytics, and communication strategies under uncertainty.
        </p>
        <p>
            My research bridges control room operations, cognitive science, and data-driven design, leveraging techniques such as cognitive load detection, microsaccade detection, and gaze- and voice-based collaboration tools. I am passionate about designing intelligent, resilient interfaces that enhance teamwork, situational awareness, and operator well-being in high-stakes environments.
        </p>
        <p>
            I am currently expanding this work through the Digital Cabin Emergency Evacuation Trainer (D-CEET) project, developing VR-based training for airline crew members. My research focuses on validating the effectiveness of digital twin training concepts using eye-tracking, physiological sensing, and behavioural analytics to assess cognitive load, situational awareness, and collaborative decision-making during high-stakes emergency scenarios.
        </p>
        <p>
            <a href="https://scholar.google.com/citations?user=T7ciEg8AAAAJ&hl=en/" target="_blank">@Google Scholar</a>
        </p>

        <blockquote>
            Advancing decision-making under uncertainty through humanâ€“computer interaction and visualization.
        </blockquote>

        <!-- Buttons -->
        <ul class="actions special">
            <li><a href="#news" class="button">Current Work</a></li>
            <li><a href="#current" class="button">Published Work</a></li>
            <li>
                <a
                  href="https://raw.githubusercontent.com/suvodip1212/webpage/main/files/cv-suvodip%20Chakraborty.pdf"
                  download="cv-suvodip-Chakraborty"
                  class="button"
                  onclick="trackCVDownload()">
                  Download CV
                </a>
            </li>
        </ul>
    </section>

    <!-- News Section -->
    <section id="news">
        <h3>News</h3>
        <div class="table-wrapper">
            <table class="alt">
                <tbody>
                    <tr><td><strong>Dec 2025</strong></td><td>Paper on <em>collaboration</em> accepted in IJHCI.</td></tr>
                    <tr><td><strong>April 2025</strong></td><td>Started Postdoc at ETH Zurich.</td></tr>
                    <tr><td><strong>March 2025</strong></td><td>Defended PhD thesis at ETH Zurich.</td></tr>
                    <tr><td><strong>Aug 2024</strong></td><td>Paper on <em>cognitive load detection</em> at IEEE THMS.</td></tr>
                </tbody>
            </table>
        </div>
    </section>

    <!-- Published Work Section -->
    <section id="current">
        <h2>Recent Work</h2>
        <p>You can check out my selected previous works below ðŸ˜‰</p>
        <div class="row">
            <!-- Paper 1 -->
            <article class="col-6 col-12-xsmall work-item">
                <a href="https://www.tandfonline.com/doi/full/10.1080/10447318.2025.2594138" class="image fit thumb" target="_blank">
                    <img src="images/collaboration.png" alt="Beyond Words: Eye-Gaze Sharing on Collaboration and Cognitive Load"/>
                </a>
                <a href="https://www.tandfonline.com/doi/full/10.1080/10447318.2025.2594138" target="_blank">
                    Beyond Words: The Impact of Eye-Gaze Sharing on Collaboration and Cognitive Load
                </a>
                <p style="text-align:justify">
                    This study investigates collaboration under high workload conditions. Teams sharing eye gaze information outperform speech-only collaboration, reducing cognitive load and improving coordination when everyone is under pressure.
                </p>
            </article>

            <!-- Paper 2 -->
            <article class="col-6 col-12-xsmall work-item">
                <a href="https://ieeexplore.ieee.org/document/10629234" class="image fit thumb" target="_blank">
                    <img src="images/thms.png" alt="Estimating Mental Workload from Eye-Tracking"/>
                </a>
                <a href="https://ieeexplore.ieee.org/document/10629234" target="_blank">
                    Estimating Perceived Mental Workload From Eye-Tracking Data Based on Benign Anisocoria
                </a>
                <p style="text-align:justify">
                    This paper introduces two new eye-tracking metrics based on subtle left-right pupil differences, providing an accurate assessment of cognitive load. The approach was validated using an N-back test, showing reliable workload measurement.
                </p>
            </article>

            <!-- Paper 3 -->
            <article class="col-6 col-12-xsmall work-item">
                <a href="https://www.tandfonline.com/doi/full/10.1080/13658816.2024.2348747" class="image fit thumb" target="_blank">
                    <img src="images/BA.jpg" alt="Uncertainty Visualization on Cognitive Load"/>
                </a>
                <a href="https://www.tandfonline.com/doi/full/10.1080/13658816.2024.2348747" target="_blank">
                    The influence of uncertainty visualization on cognitive load in a safety- and time-critical decision-making task
                </a>
                <p style="text-align:justify">
                    This study explores how different visualization techniques reduce cognitive load for traffic controllers and professionals in safety-critical domains. Eye-tracking data shows that decision-making improves when uncertainty is visualized effectively.
                </p>
            </article>

            <!-- Paper 4 -->
            <article class="col-6 col-12-xsmall work-item">
                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0167865517304075" class="image fit thumb" target="_blank">
                    <img src="images/figure_1.jpg" alt="Localization of Eye Saccadic Signatures"/>
                </a>
                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0167865517304075" target="_blank">
                    Localization of eye saccadic signatures in electrooculograms using sparse representations with data-driven dictionaries
                </a>
                <p style="text-align:justify">
                    We propose two methods to localize saccadic eye movement signatures in EOG recordings using sparse representations and dynamic time warping, offering fast and accurate approaches for context-specific applications.
                </p>
            </article>

            <!-- Paper 5 -->
            <article class="col-6 col-12-xsmall work-item">
                <a href="https://ieeexplore.ieee.org/abstract/document/8487864" class="image fit thumb" target="_blank">
                    <img src="images/figure_3.png" alt="Analysis of Electrooculography Electrodes"/>
                </a>
                <a href="https://ieeexplore.ieee.org/abstract/document/8487864" target="_blank">
                    Modeling and Analysis of Electrodes for Electrooculography
                </a>
                <p style="text-align:justify">
                    This work compares electrodes of different materials (Copper, Gold, Silver, Ag-AgCl) for EOG applications, proposing a low-cost dry electrode assembly that ensures better signal quality and user comfort.
                </p>
            </article>

            <!-- Paper 6 -->
            <article class="col-6 col-12-xsmall work-item">
                <a href="https://ieeexplore.ieee.org/abstract/document/8589865" class="image fit thumb" target="_blank">
                    <img src="images/figure_2.png" alt="Active Sensors for Physiological Signals"/>
                </a>
                <a href="https://ieeexplore.ieee.org/abstract/document/8589865" target="_blank">
                    Active Sensors for the Acquisition of Physiological Signals
                </a>
                <p style="text-align:justify">
                    This paper presents gold-plated copper electrodes with active compensation for acquiring EEG, EOG, and ECG signals, addressing common challenges in physiological signal acquisition and providing a composite database for research.
                </p>
            </article>
        </div>
    </section>

</div>

<!-- Footer -->
<footer id="footer">
    <div class="inner">
        <ul class="copyright">
            <li>&copy; Suvodip Chakraborty</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
        </ul>
    </div>
</footer>

<!-- Scripts -->
<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/jquery.poptrox.min.js"></script>
<script src="assets/js/browser.min.js"></script>
<script src="assets/js/breakpoints.min.js"></script>
<script src="assets/js/util.js"></script>
<script src="assets/js/main.js"></script>

</body>
</html>
